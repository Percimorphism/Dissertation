@article{lu&peng,
  author =       {Lu, L. and Peng, X.},
  title =     {Spectra of edge-independent random graphs},
  journal =      {The Electronic Journal of Combinatorics},
  volume =       20,
  number =       4,
  pages =        {1-17},
  year =         "2013",
}

@article{vD-K,
  author =       {Yu, Y. and Wang, T. and Samworth, R. J.},
  title =     {A useful variant of the {D}avis-{K}ahan theorem for statisticians},
  journal =      {Biometrika},
  volume =       102,
  pages =        {351-323},
  year =         "2015",
}

@article{D-K,
  author =       {Davis, C. and Kahan, W, M.},
  title =     {The rotation of eigenvectors by a perturbation {III}},
  journal =      {SIAM Journal of Numerical Analysis},
  volume =       7,
  pages =        {1-46},
  year =         "1970",
}

@incollection{Leeuw-Heiser,
  author      = "de Leeuw, J. and Heiser, W.",
  title       = "Theory of multidimensional scaling",
  editor      = "Krishnaiah, P.R. and Kanal, L.",
  booktitle   = "Handbook of Statistics II",
  publisher   = "North Holland Publishing Company",
  address     = "Amsterdam, The Netherlands",
  year        = 1982,
  pages       = "285-316",
}

@article{CDCHSB,
  author =       { Lyzinski, V. and Tang, M. and Athreya, A. and Park, Y. and Priebe, C.},
  title =     {Community Detection and Classification in Hierarchical Stochastic Blockmodels},
  journal =      {IEEE Transactions on Network Science and Engineering},
  volume =       4,
  pages =        {13-26},
  year =         "2017",
}

@article{Torgerson,
  author =       {Torgerson, W. S.},
  title =     {Multidimensional scaling: I.  theory and method},
  journal =      {Psychometrika},
  volume =       17,
  pages =        {401-419},
  year =         "1952",
}

@book{BGbook,
    author    = {Borg, I. and Groenen, P. J. F.},
    title     = {Modern Multidimensional Scaling: Theory and Applications},
    year      = "2005",
    publisher = "Springer",
    address   = "New York"
}

@article{RDPGJMLR,
  author  = {Avanti Athreya and Donniell E. Fishkind and Minh Tang and Carey E. Priebe and Youngser Park and Joshua T. Vogelstein and Keith Levin and Vince Lyzinski and Yichen Qin and Daniel L Sussman},
  title   = {Statistical Inference on Random Dot Product Graphs: a Survey},
  journal = {Journal of Machine Learning Research},
  year    = {2018},
  volume  = {18},
  number  = {226},
  pages   = {1-92},
  url     = {http://jmlr.org/papers/v18/17-448.html}
}


@misc{Fan,
   author = {Fan, J. and Sun, Q. and Zhou, W. X. and Zhu, Z.},
    title = "{Principal component analysis for big data}",
  journal = {ArXiv e-prints},
   archivePrefix = "arXiv",
   note = {arXiv:1801.01602},
   primaryClass = "stat.ME",
   keywords = {Statistics - Methodology},
     year = 2018,
    month = jan,
   adsurl = {http://adsabs.harvard.edu/abs/2018arXiv180101602F},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@misc{Peterfreund&Gavish,
   author = {{Peterfreund}, E. and {Gavish}, M.},
    title = "{Multidimensional Scaling of Noisy High Dimensional Data}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   note = {arXiv:1801.10229},
 primaryClass = "math.ST",
 keywords = {Mathematics - Statistics Theory},
     year = 2018,
    month = jan,
   adsurl = {http://adsabs.harvard.edu/abs/2018arXiv180110229P},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@book{dissimilarityPatternRecog,
    author    = {Pekalska, E. and Duin, R. P. W.},
    title     = {The Dissimilarity Representation for Pattern Recognition: Foundations and Applications},
    year      = "2005",
    publisher = "World Scientific Publishing Company Inc",
    address   = "Singapore"
}

@book{Jackson,
    author    = {Jackson, J. E.},
    title     = {A User's Guide to Principal Components},
    year      = "1991",
    publisher = "Wiley \& Sons",
    address = "New York"
}

@article{FastEmbeddingJOFCrawstress,
author = {Lyzinski, V. and Park, Y. and Priebe, C. E. and Trosset, M.},
title = {Fast Embedding for {JOFC} Using the Raw Stress Criterion},
journal = {Journal of Computational and Graphical Statistics},
volume = {26},
number = {4},
pages = {786-802},
year  = {2017},
publisher = {Taylor & Francis},
doi = {10.1080/10618600.2017.1321551},
URL = { https://doi.org/10.1080/10618600.2017.1321551},
eprint = { https://doi.org/10.1080/10618600.2017.1321551}
}

@article{Zhu&Ghodsi,
  title = {Automatic dimensionality selection from the scree plot via the use of profile likelihood},
  journal = {Computational Statistics and Data Analysis},
  volume ={51},
  number = {2},
  pages = {918 - 930},
  year = {2006},
  author = {Zhu, M. and Ghodsi, A.}
}

@article{Chatterjee,
author = {Chatterjee, S.},
title = {MATRIX ESTIMATION BY UNIVERSAL SINGULAR VALUE THRESHOLDING},
journal = {The Annals of Statistics},
volume = {43},
number = {1},
pages = {177-214},
year  = {2015},
publisher = {Institute of Mathematical Statistics},
doi = {10.1214/14-AOS1272},
}

@article{Glaunes2008,
year={2008},
issn={0920-5691},
journal={International Journal of Computer Vision},
volume={80},
number={3},
title={Large Deformation Diffeomorphic Metric Curve Mapping},
url={http://dx.doi.org/10.1007/s11263-008-0141-9},
publisher={Springer US},
keywords={Large deformation; Diffeomorphisms; Vector-valued measure; Curve matching},
author={Glaun\`{e}s, J. and Qiu, A. and Miller, M. I. and Younes, L.},
pages={317-336},
language={English}
}

@article{Kaltenmark2017,
        author = {Kaltenmark, I. and Charlier, B. and Charon, N.},
        title = {A general framework for curve and surface comparison and registration with oriented varifolds},
        journal = {Computer Vision and Pattern Recognition (CVPR)},
	volume={},
	number={},
	pages={},
        year = {2017},
	abstract = {}
}

@book{HDP,
  author = {Vershynin, R.},
  title = {High-Dimensional Probability An Introduction with Applications in Data Science},
  year = 2018,
  url = {https://www.math.uci.edu/~rvershyn/papers/HDP-book/HDP-book.pdf},
  urldate = {2018-03-01}
}

@misc{OMNI,
   author = {Levin, K. and Athreya, A. and Tang, M. and Lyzinski, V. and Priebe, C. E.},
   title = "{A central limit theorem for an omnibus embedding of random dot product graphs}",
   journal = {ArXiv e-prints},
   archivePrefix = "arXiv",
   note = {arXiv:1705.09355},
   primaryClass = "stat.ME",
   keywords = {Statistics - Methodology},
   year = 2017,
   month = 05
}


@article{DsquaredplusE,
author = {Zhang, L. and Wahba, G. and Yuan, M.},
title = {Distance shrinkage and {E}uclidean embedding via regularized kernel estimation},
journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
volume = {78},
year = {2016},
number = {4},
pages = {849-867},
keywords = {Embedding, Euclidean distance matrix, Kernel, Multi-dimensional scaling, Regularization, Shrinkage, Trace norm},
doi = {10.1111/rssb.12138},
url = {https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/rssb.12138},
eprint = {https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/rssb.12138}
}

@article {Isomap,
	author = {Tenenbaum, J. B. and Silva, V. D. and Langford, J. C.},
	title = {A Global Geometric Framework for Nonlinear Dimensionality Reduction},
	volume = {290},
	number = {5500},
	pages = {2319--2323},
	year = {2000},
	doi = {10.1126/science.290.5500.2319},
	publisher = {American Association for the Advancement of Science},
	issn = {0036-8075},
	URL = {http://science.sciencemag.org/content/290/5500/2319},
	eprint = {http://science.sciencemag.org/content/290/5500/2319.full.pdf},
	journal = {Science}
}

@article{Scholkopf,
author = {Sch\"{o}lkopf, B. and Smola, A. and M\"{u}ller, K.-R.},
title = {Nonlinear Component Analysis as a Kernel Eigenvalue Problem},
journal = {Neural Computation},
volume = {10},
number = {5},
pages = {1299-1319},
year = {1998},
doi = {10.1162/089976698300017467},
URL = { https://doi.org/10.1162/089976698300017467    },
eprint = {https://doi.org/10.1162/089976698300017467    }
}

@article{ChenBuja,
author = {Chen, L. and Buja, A.},
title = {Local Multidimensional Scaling for Nonlinear Dimension Reduction, Graph Drawing, and Proximity Analysis},
journal = {Journal of the American Statistical Association},
volume = {104},
number = {485},
pages = {209-219},
year  = {2009},
publisher = {Taylor & Francis},
doi = {10.1198/jasa.2009.0111},
URL = {https://doi.org/10.1198/jasa.2009.0111    },
eprint = {https://doi.org/10.1198/jasa.2009.0111}
}

@Article{Alfakih1999,
author={Alfakih, A. Y. and Khandani, A. and Wolkowicz, H.},
title="Solving {E}uclidean Distance Matrix Completion Problems Via Semidefinite Programming",
journal="Computational Optimization and Applications",
year="1999",
month="Jan",
day="01",
volume="12",
number="1",
pages="13--30",
issn="1573-2894",
doi="10.1023/A:1008655427845",
url="https://doi.org/10.1023/A:1008655427845"
}

@article{Bakonyi,
author = {Bakonyi, M. and Johnson, C.},
title = {The {E}uclidian Distance Matrix Completion Problem},
journal = {SIAM Journal on Matrix Analysis and Applications},
volume = {16},
number = {2},
pages = {646-654},
year = {1995},
doi = {10.1137/S0895479893249757},
URL = {https://doi.org/10.1137/S0895479893249757   },
eprint = {https://doi.org/10.1137/S0895479893249757}
}

@article {Singer9507,
	author = {Singer, A.},
	title = {A remark on global positioning from local distances},
	volume = {105},
	number = {28},
	pages = {9507--9511},
	year = {2008},
	doi = {10.1073/pnas.0709842104},
	publisher = {National Academy of Sciences},
	issn = {0027-8424},
	URL = {http://www.pnas.org/content/105/28/9507},
	eprint = {http://www.pnas.org/content/105/28/9507.full.pdf},
	journal = {Proceedings of the National Academy of Sciences}
}

@Article{Spence1974,
author={Spence, I. and Domoney, D. W.},
title="Single subject incomplete designs for nonmetric multidimensional scaling",
journal="Psychometrika",
year="1974",
month="Dec",
day="01",
volume="39",
number="4",
pages="469--490",
issn="1860-0980",
doi="10.1007/BF02291669",
url="https://doi.org/10.1007/BF02291669"
}

@Article{Javanmard2013,
author={Javanmard, A. and Montanari, A.},
title="Localization from Incomplete Noisy Distance Measurements",
journal="Foundations of Computational Mathematics",
year="2013",
month="Jun",
day="01",
volume="13",
number="3",
pages="297--345",
issn="1615-3383",
doi="10.1007/s10208-012-9129-5",
url="https://doi.org/10.1007/s10208-012-9129-5"
}

@INPROCEEDINGS{Montanari, 
author={Oh, S. and Montanari, A. and Karbasi, A.}, 
booktitle={2010 IEEE Information Theory Workshop on Information Theory (ITW 2010, Cairo)}, 
title={Sensor network localization from local connectivity: Performance analysis for the MDS-MAP algorithm}, 
year={2010}, 
volume={}, 
number={}, 
pages={1-5}, 
keywords={maximum likelihood estimation;wireless sensor networks;MDS-MAP algorithm;local connectivity;multidimensional scaling;range-based model;sensor network localization;wireless sensor networks;Algorithm design and analysis;Analytical models;Costs;Information analysis;Matrix converters;Multidimensional systems;Performance analysis;Sensor systems;Statistical analysis;Wireless sensor networks}, 
doi={10.1109/ITWKSPS.2010.5503144}, 
ISSN={}, 
month={Jan},}

@article{Taghizadeh,
      title = {Theoretical Analysis of {E}uclidean Distance Matrix  Completion for Ad hoc Microphone Array Calibration},
      author = {Taghizadeh, M. J.},
      publisher = {Idiap},
      year = {2014},
      abstract = {We consider the problem of ad~hoc microphone array  calibration where the distance matrix consisted of all  microphones pairwise distances have entries missing  corresponding to distances greater than $d_{\text{max}}$.  Furthermore, the known entries are noisy modeled through  additive independent random variables with strictly  sub-Gaussian distribution, $\textsc{S}\textsc{ub}(c^2(d))$  with a bounded constant dependent on the distance $d$  between the microphone pairs. In this report, we exploit  matrix completion approach to recover the full distance  matrix. We derive the theoretical guarantees of microphone  calibration performance which demonstrates that the error  of calibrating a network of $N$ microphones using matrix  completion decreases as $\mathcal{O}(N^{-1/2})$.},
}

@Article{RandomForestBreiman,
author="Breiman, L.",
title="Random Forests",
journal="Machine Learning",
year="2001",
month="Oct",
day="01",
volume="45",
number="1",
pages="5--32",
abstract="Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund {\&} R. Schapire, Machine Learning: Proceedings of the Thirteenth International conference, ***, 148--156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression.",
issn="1573-0565",
doi="10.1023/A:1010933404324",
url="https://doi.org/10.1023/A:1010933404324"
}

@article{Tasissa2018ExactRO,
  title={Exact Reconstruction of {E}uclidean Distance Geometry Problem Using Low-rank Matrix Completion},
  author={Tasissa, A. and Lai, R.},
  journal={CoRR},
  year={2018},
  volume={abs/1804.04310}
}

@incollection{CriminisiandShotton,
  author      = "Criminisi, A. and Shotton, J.",
  title       = "Manifold Forests",
  editor      = "Criminisi, A. and Shotton, J.",
  booktitle   = "Decision Forests for Computer Vision and Medical Image Analysis",
  publisher   = "Springer",
  address     = "London",
  year        = 2013,
  pages       = "79-94",
  chapter     = 7,
}

@article {Vogelstein386,
	author = {Vogelstein, J. T. and Park, Y. and Ohyama, T. and Kerr, R. A. and Truman, J. W. and Priebe, C. E. and Zlatic, M.},
	title = {Discovery of Brainwide Neural-Behavioral Maps via Multiscale Unsupervised Structure Learning},
	volume = {344},
	number = {6182},
	pages = {386--392},
	year = {2014},
	doi = {10.1126/science.1250298},
	publisher = {American Association for the Advancement of Science},
	abstract = {Mapping functional neural circuits for many behaviors has been almost impossible, so Vogelstein et al. (p. 386, published online 27 March; see the Perspective by O{\textquoteright}Leary and Marder) developed a broadly applicable optogenetic method for neuron-behavior mapping and used it to phenotype larval Drosophila and thus developed a reference atlas. As optogenetic experiments become routine in certain fields of neuroscience research, creating even more specialized tools is imperative (see the Perspective by Hayashi). By engineering channelrhodopsin, Wietek et al. (p. 409, published online 27 March) and Berndt et al. (p. 420) created two different light-gated anion channels to block action potential generation during synaptic stimulation or depolarizing current injections. These new tools not only improve understanding of channelrhodopsins but also provide a way to silence cells. A single nervous system can generate many distinct motor patterns. Identifying which neurons and circuits control which behaviors has been a laborious piecemeal process, usually for one observer-defined behavior at a time. We present a fundamentally different approach to neuron-behavior mapping. We optogenetically activated 1054 identified neuron lines in Drosophila larvae and tracked the behavioral responses from 37,780 animals. Application of multiscale unsupervised structure learning methods to the behavioral data enabled us to identify 29 discrete, statistically distinguishable, observer-unbiased behavioral phenotypes. Mapping the neural lines to the behavior(s) they evoke provides a behavioral reference atlas for neuron subsets covering a large fraction of larval neurons. This atlas is a starting point for connectivity- and activity-mapping studies to further investigate the mechanisms by which neurons mediate diverse behaviors.},
	issn = {0036-8075},
	URL = {http://science.sciencemag.org/content/344/6182/386},
	eprint = {http://science.sciencemag.org/content/344/6182/386.full.pdf},
	journal = {Science}
}

@Article{Carroll1970,
author="Carroll, J. D. and Chang, J.-J.",
title="Analysis of individual differences in multidimensional scaling via an $n$-way generalization of ``{E}ckart-{Y}oung'' decomposition",
journal="Psychometrika",
year="1970",
month="Sep.",
day="01",
volume="35",
number="3",
pages="283--319",
abstract="An individual differences model for multidimensional scaling is outlined in which individuals are assumed differentially to weight the several dimensions of a common ``psychological space''. A corresponding method of analyzing similarities data is proposed, involving a generalization of ``Eckart-Young analysis'' to decomposition of three-way (or higher-way) tables. In the present case this decomposition is applied to a derived three-way table of scalar products between stimuli for individuals. This analysis yields a stimulus by dimensions coordinate matrix and a subjects by dimensions matrix of weights. This method is illustrated with data on auditory stimuli and on perception of nations.",
issn="1860-0980",
doi="10.1007/BF02310791",
url="https://doi.org/10.1007/BF02310791"
}

@article{cmdsecon,
    author = {Machado, J. A. T. and Mata, M. E.},
    journal = {PLOS ONE},
    publisher = {Public Library of Science},
    title = {Analysis of World Economic Variables Using Multidimensional Scaling},
    year = {2015},
    month = {03},
    volume = {10},
    url = {https://doi.org/10.1371/journal.pone.0121277},
    pages = {1-17},
    abstract = {Waves of globalization reflect the historical technical progress and modern economic growth. The dynamics of this process are here approached using the multidimensional scaling (MDS) methodology to analyze the evolution of GDP per capita, international trade openness, life expectancy, and education tertiary enrollment in 14 countries. MDS provides the appropriate theoretical concepts and the exact mathematical tools to describe the joint evolution of these indicators of economic growth, globalization, welfare and human development of the world economy from 1977 up to 2012. The polarization dance of countries enlightens the convergence paths, potential warfare and present-day rivalries in the global geopolitical scene.},
    number = {3},
    doi = {10.1371/journal.pone.0121277}
}

@book{Bishop2006,
 author = {Bishop, C. M.},
 title = {Pattern Recognition and Machine Learning (Information Science and Statistics)},
 year = {2006},
 isbn = {0387310738},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
} 

@book{ESL,
  added-at = {2008-05-16T16:17:42.000+0200},
  address = {New York, NY, USA},
  author = {Hastie, T. and Tibshirani, R. and Friedman, J.},
  biburl = {https://www.bibsonomy.org/bibtex/2f58afc5c9793fcc8ad8389824e57984c/sb3000},
  interhash = {d585aea274f2b9b228fc1629bc273644},
  intrahash = {f58afc5c9793fcc8ad8389824e57984c},
  keywords = {ml statistics},
  publisher = {Springer New York Inc.},
  series = {Springer Series in Statistics},
  timestamp = {2008-05-16T16:17:43.000+0200},
  title = {The Elements of Statistical Learning},
  year = 2001
}

@book{MurphyML,
 author = {Murphy, K. P.},
 title = {Machine Learning: A Probabilistic Perspective},
 year = {2012},
 isbn = {0262018020, 9780262018029},
 publisher = {The MIT Press},
} 

@Inbook{Cox2008,
author="Cox, M. A. A.
and Cox, T. F.",
title="Multidimensional Scaling",
bookTitle="Handbook of Data Visualization",
year="2008",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="315--347",
abstract="Suppose dissimilarity data have been collected on a set of n objects or individuals, where there is a value of dissimilarity measured for each pair.The dissimilarity measure used might be a subjective judgement made by a judge, where for example a teacher subjectively scores the strength of friendship between pairs of pupils in her class, or, as an alternative, more objective, measure, she might count the number of contacts made in a day between each pair of pupils. In other situations the dissimilarity measure might be based on a data matrix. The general aim of multidimensional scaling is to find a configuration of points in a space, usually Euclidean, where each point represents one of the objects or individuals, and the distances between pairs of points in the configuration match as well as possible the original dissimilarities between the pairs of objects or individuals. Such configurations can be found using metric and non-metric scaling, which are covered in Sects. 2 and 3. A number of other techniques are covered by the umbrella title of multidimensional scaling (MDS), and here the techniques of Procrustes analysis, unidimensional scaling, individual differences scaling, correspondence analysis and reciprocal averaging are briefly introduced and illustrated with pertinent data sets.",
isbn="978-3-540-33037-0",
doi="10.1007/978-3-540-33037-0_14",
url="https://doi.org/10.1007/978-3-540-33037-0_14"
}

@Article{Athreya2016,
author="Athreya, A.
and Priebe, C. E.
and Tang, M.
and Lyzinski, V.
and Marchette, D. J.
and Sussman, D. L.",
title="A Limit Theorem for Scaled Eigenvectors of Random Dot Product Graphs",
journal="Sankhya A",
year="2016",
month="Feb",
day="01",
volume="78",
number="1",
pages="1--18",
abstract="We prove a central limit theorem for the components of the largest eigenvectors of the adjacency matrix of a finite-dimensional random dot product graph whose true latent positions are unknown. We use the spectral embedding of the adjacency matrix to construct consistent estimates for the latent positions, and we show that the appropriately scaled differences between the estimated and true latent positions converge to a mixture of Gaussian random variables. We state several corollaries, including an alternate proof of a central limit theorem for the first eigenvector of the adjacency matrix of an Erdos-R{\'e}nyi random graph.",
issn="0976-8378",
doi="10.1007/s13171-015-0071-x",
url="https://doi.org/10.1007/s13171-015-0071-x"
}

@ARTICLE{wirelesssensor, 
author={N. Patwari and J. N. Ash and S. Kyperountas and A. O. Hero and R. L. Moses and N. S. Correal}, 
journal={IEEE Signal Processing Magazine}, 
title={Locating the nodes: cooperative localization in wireless sensor networks}, 
year={2005}, 
volume={22}, 
number={4}, 
pages={54-69}, 
keywords={wireless sensor networks;statistical analysis;time-of-arrival estimation;direction-of-arrival estimation;ultra wideband communication;signal processing;synchronisation;covariance matrices;distributed algorithms;cooperative localization;wireless sensor network;sensor localization system;measurement-based statistical model;time-of-arrival measurement;angle-of-arrival measurement;received-signal-strength;ultrawideband measurement;wideband measurement;acoustic media;location estimation;statistical signal processing;synchronization;covariance matrix;distributed algorithm;centralized algorithm;Wireless sensor networks;Sensor systems;Communication system traffic control;Monitoring;Costs;Global Positioning System;Robustness;Wireless LAN;Sensor phenomena and characterization;Ash}, 
doi={10.1109/MSP.2005.1458287}, 
ISSN={1053-5888}, 
month={July},}
