\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Classical Multidimensional Scaling under Noise}{6}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{sec:dmcs}{{2}{6}{Classical Multidimensional Scaling under Noise}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Review of Classical Multidimensional Scaling}{6}{section.2.1}}
\newlabel{sec:cmds}{{2.1}{6}{Review of Classical Multidimensional Scaling}{section.2.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Noise Models and Embedding}{7}{section.2.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Model 1: $\Delta ^2 = D^2 + E$}{7}{subsection.2.2.1}}
\newlabel{sec:M&E}{{2.2.1}{7}{Model 1: $\Delta ^2 = D^2 + E$}{subsection.2.2.1}{}}
\citation{DsquaredplusE}
\citation{Javanmard2013,Chatterjee,Alfakih1999,wirelesssensor}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Model 2: $\Delta = D + E$}{8}{subsection.2.2.2}}
\newlabel{D+E}{{2.2.2}{8}{Model 2: $\Delta = D + E$}{subsection.2.2.2}{}}
\citation{DsquaredplusE}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Model 3: Matrix Completion}{9}{subsection.2.2.3}}
\newlabel{matrix_completion}{{2.2.3}{9}{Model 3: Matrix Completion}{subsection.2.2.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Related Works}{9}{section.2.3}}
\newlabel{RW}{{2.3}{9}{Related Works}{section.2.3}{}}
\citation{DsquaredplusE}
\citation{Alfakih1999,Bakonyi,Singer9507,Spence1974}
\citation{BGbook,Chatterjee,Javanmard2013,Montanari}
\citation{Chatterjee}
\newlabel{eq:zhang}{{2.1}{10}{Related Works}{equation.2.3.1}{}}
\citation{Taghizadeh}
\citation{Tasissa2018ExactRO}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Main Theorems}{12}{section.2.4}}
\newlabel{main}{{2.4}{12}{Main Theorems}{section.2.4}{}}
\newlabel{main_theorem_D^2+E}{{2.4.1}{13}{Main Theorems}{fact.2.4.1}{}}
\newlabel{main_theorem_D+E}{{2.4.3}{14}{Main Theorems}{fact.2.4.3}{}}
\newlabel{main_theorem_matrix_completion}{{2.4.4}{15}{Main Theorems}{fact.2.4.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Empirical Results}{16}{section.2.5}}
\newlabel{ER}{{2.5}{16}{Empirical Results}{section.2.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.1}Three Point-mass Simulated Data}{16}{subsection.2.5.1}}
\newlabel{SD}{{2.5.1}{16}{Three Point-mass Simulated Data}{subsection.2.5.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces Empirical average of covariance matrix $\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle \Sigma $}\mathaccent "0362{\Sigma }^{(1)}$, and entry-wise variance (500 simulations).\relax }}{17}{table.caption.7}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:cov_1}{{2.1}{17}{Empirical average of covariance matrix $\hat {\Sigma }^{(1)}$, and entry-wise variance (500 simulations).\relax }{table.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Simulation results for $n$=50, 100, 500 and 1000 points, as described in Section \ref  {SD}. The blue ellipses are the 95\% level curves of the empirical covariance matrix, and the blue dots are the empirical centers for three classes. The black dots are the true positions of $x_1$, $x_2$ and $x_3$, and the black ellipses are the 95\% level curve for the theoretical covariance matrices as in Theorem \ref  {main_theorem_D+E}. Note that the blue and black centers and ellipses coincide for large $n$.\relax }}{18}{figure.caption.8}}
\newlabel{fig:Simulation result}{{2.1}{18}{Simulation results for $n$=50, 100, 500 and 1000 points, as described in Section \ref {SD}. The blue ellipses are the 95\% level curves of the empirical covariance matrix, and the blue dots are the empirical centers for three classes. The black dots are the true positions of $x_1$, $x_2$ and $x_3$, and the black ellipses are the 95\% level curve for the theoretical covariance matrices as in Theorem \ref {main_theorem_D+E}. Note that the blue and black centers and ellipses coincide for large $n$.\relax }{figure.caption.8}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {$n$=50}}}{18}{subfigure.1.1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {$n$=100}}}{18}{subfigure.1.2}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {$n$=500}}}{18}{subfigure.1.3}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {$n$=1000}}}{18}{subfigure.1.4}}
\citation{Glaunes2008}
\citation{Kaltenmark2017}
\citation{Kaltenmark2017}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.2}Shape clustering}{19}{subsection.2.5.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Examples from the Kimia Dataset.\relax }}{19}{figure.caption.9}}
\newlabel{fig:bottle_bone_wrench}{{2.2}{19}{Examples from the Kimia Dataset.\relax }{figure.caption.9}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Bottle}}}{19}{subfigure.2.1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Bone}}}{19}{subfigure.2.2}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {Wrench}}}{19}{subfigure.2.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Noisy versions of examples from the Kimia Dataset.\relax }}{20}{figure.caption.10}}
\newlabel{fig:noisy_bottle_bone_wrench}{{2.3}{20}{Noisy versions of examples from the Kimia Dataset.\relax }{figure.caption.10}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Bottle}}}{20}{subfigure.3.1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Bone}}}{20}{subfigure.3.2}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {Wrench}}}{20}{subfigure.3.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Pairs plot of CMDS into $\mathbb  {R}^3$ for the noisy curves. Colors correspond to the different classes (blue for bottle, red for bone, and orange for wrench). The position of the nine template curves in the configuration are highlighted with large black dots.\relax }}{21}{figure.caption.11}}
\newlabel{fig:large currents}{{2.4}{21}{Pairs plot of CMDS into $\mathbb {R}^3$ for the noisy curves. Colors correspond to the different classes (blue for bottle, red for bone, and orange for wrench). The position of the nine template curves in the configuration are highlighted with large black dots.\relax }{figure.caption.11}{}}
\citation{Athreya2016}
\citation{OMNI}
\citation{Fan}
\citation{Peterfreund&Gavish}
\citation{Zhu&Ghodsi,Jackson,Chatterjee}
\@writefile{toc}{\contentsline {section}{\numberline {2.6}Discussion}{22}{section.2.6}}
\newlabel{D}{{2.6}{22}{Discussion}{section.2.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Simulation of CMDS with heteroscedastic noise $\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle E$}\mathaccent "0365{E}$. The black dots are the true positions for the three points. The blue dots are the empirical means and the blue ellipses are the 95\% level curve of the empirical covariance matrix. Note that $\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle E$}\mathaccent "0365{E}$ used in this simulation is of the same order for the off-diagonal blocks as that used in Figure \ref  {fig:Simulation result}. NB: there is asymptotic bias.\relax }}{23}{figure.caption.12}}
\newlabel{fig:Uncommon_var_E}{{2.5}{23}{Simulation of CMDS with heteroscedastic noise $\widetilde {E}$. The black dots are the true positions for the three points. The blue dots are the empirical means and the blue ellipses are the 95\% level curve of the empirical covariance matrix. Note that $\widetilde {E}$ used in this simulation is of the same order for the off-diagonal blocks as that used in Figure \ref {fig:Simulation result}. NB: there is asymptotic bias.\relax }{figure.caption.12}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {$n$=50}}}{23}{subfigure.5.1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {$n$=100}}}{23}{subfigure.5.2}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {$n$=500}}}{23}{subfigure.5.3}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {$n$=1000}}}{23}{subfigure.5.4}}
\citation{Leeuw-Heiser}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Simulation of MDS using raw stress criterion for $n$=50, 100, 500 and 1000 points. The black dots are the true positions of $x_1$, $x_2$ and $x_3$, the blue dots are the empirical mean of the simulation and the blue ellipses are the 95\% level curve of the empirical covariance matrix.\relax }}{25}{figure.caption.13}}
\newlabel{fig:RawStress}{{2.6}{25}{Simulation of MDS using raw stress criterion for $n$=50, 100, 500 and 1000 points. The black dots are the true positions of $x_1$, $x_2$ and $x_3$, the blue dots are the empirical mean of the simulation and the blue ellipses are the 95\% level curve of the empirical covariance matrix.\relax }{figure.caption.13}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {$n$=50}}}{25}{subfigure.6.1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {$n$=100}}}{25}{subfigure.6.2}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {$n$=500}}}{25}{subfigure.6.3}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {$n$=1000}}}{25}{subfigure.6.4}}
\citation{OMNI}
\citation{OMNI}
\@writefile{toc}{\contentsline {section}{\numberline {2.7}Conjecture: CMDS on Omni Embedding of graphs and Hypothesis Testing}{26}{section.2.7}}
\citation{OMNI}
\@writefile{toc}{\contentsline {section}{\numberline {2.8}Proof of the Theorems}{28}{section.2.8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.8.1}Proof of Theorem \ref  {main_theorem_D+E}}{28}{subsection.2.8.1}}
\newlabel{proof}{{2.8.1}{28}{Proof of Theorem \ref {main_theorem_D+E}}{subsection.2.8.1}{}}
\newlabel{appthm1}{{2.8.1}{28}{Proof of Theorem \ref {main_theorem_D+E}}{fact.2.8.1}{}}
\newlabel{appthm2}{{2.8.2}{30}{Proof of Theorem \ref {main_theorem_D+E}}{fact.2.8.2}{}}
\newlabel{term1}{{2.3}{30}{Proof of Theorem \ref {main_theorem_D+E}}{equation.2.8.3}{}}
\newlabel{term3}{{2.4}{30}{Proof of Theorem \ref {main_theorem_D+E}}{equation.2.8.4}{}}
\newlabel{term4}{{2.5}{30}{Proof of Theorem \ref {main_theorem_D+E}}{equation.2.8.5}{}}
\newlabel{term6}{{2.6}{30}{Proof of Theorem \ref {main_theorem_D+E}}{equation.2.8.6}{}}
\newlabel{appthm3}{{2.8.3}{32}{Proof of Theorem \ref {main_theorem_D+E}}{fact.2.8.3}{}}
\newlabel{appthm4}{{2.8.4}{35}{Proof of Theorem \ref {main_theorem_D+E}}{fact.2.8.4}{}}
\newlabel{eq:1}{{2.7}{35}{Proof of Theorem \ref {main_theorem_D+E}}{equation.2.8.7}{}}
\newlabel{eq:2}{{2.8}{35}{Proof of Theorem \ref {main_theorem_D+E}}{equation.2.8.8}{}}
\newlabel{eq:3}{{2.9}{35}{Proof of Theorem \ref {main_theorem_D+E}}{equation.2.8.9}{}}
\newlabel{eq:4}{{2.10}{35}{Proof of Theorem \ref {main_theorem_D+E}}{equation.2.8.10}{}}
\newlabel{eq:5}{{2.11}{35}{Proof of Theorem \ref {main_theorem_D+E}}{equation.2.8.11}{}}
\newlabel{appthm6}{{2.8.5}{35}{Proof of Theorem \ref {main_theorem_D+E}}{fact.2.8.5}{}}
\citation{HDP}
\newlabel{appthm7}{{2.8.6}{36}{Proof of Theorem \ref {main_theorem_D+E}}{fact.2.8.6}{}}
\citation{HDP}
\newlabel{appthm8}{{2.8.7}{37}{Proof of Theorem \ref {main_theorem_D+E}}{fact.2.8.7}{}}
\citation{D-K}
\newlabel{appthm9}{{2.8.8}{38}{Proof of Theorem \ref {main_theorem_D+E}}{fact.2.8.8}{}}
\citation{vD-K}
\citation{HDP}
\newlabel{eq:sum}{{2.12}{41}{Proof of Theorem \ref {main_theorem_D+E}}{equation.2.8.12}{}}
\newlabel{important_bound}{{2.13}{41}{Proof of Theorem \ref {main_theorem_D+E}}{equation.2.8.13}{}}
\citation{vD-K}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.8.2}Adaptation for Theorem \ref  {main_theorem_D^2+E} and \ref  {main_theorem_matrix_completion}}{45}{subsection.2.8.2}}
\newlabel{cov_D^2+E}{{2.8.9}{45}{Adaptation for Theorem \ref {main_theorem_D^2+E} and \ref {main_theorem_matrix_completion}}{fact.2.8.9}{}}
\@setckpt{chapter2}{
\setcounter{page}{48}
\setcounter{equation}{13}
\setcounter{enumi}{0}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{2}
\setcounter{section}{8}
\setcounter{subsection}{2}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{6}
\setcounter{table}{1}
\setcounter{parentequation}{0}
\setcounter{ContinuedFloat}{0}
\setcounter{KVtest}{0}
\setcounter{subfigure}{0}
\setcounter{subfigure@save}{4}
\setcounter{lofdepth}{1}
\setcounter{subtable}{0}
\setcounter{subtable@save}{0}
\setcounter{lotdepth}{1}
\setcounter{Item}{3}
\setcounter{Hfootnote}{0}
\setcounter{bookmark@seq@number}{23}
\setcounter{LT@tables}{0}
\setcounter{LT@chunks}{0}
\setcounter{inlinelisti}{0}
\setcounter{fact}{10}
\setcounter{NAT@ctr}{0}
\setcounter{float@type}{8}
\setcounter{algorithm}{0}
\setcounter{ALG@line}{0}
\setcounter{ALG@rem}{0}
\setcounter{ALG@nested}{0}
\setcounter{ALG@Lnr}{2}
\setcounter{ALG@blocknr}{10}
\setcounter{ALG@storecount}{0}
\setcounter{ALG@tmpcounter}{0}
\setcounter{section@level}{2}
}
